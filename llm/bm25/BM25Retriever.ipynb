{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61774133-ab49-486f-866d-7277b02881e6",
   "metadata": {},
   "source": [
    "# llamaIndex BM25Retriever 支持中文"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afaf835-d0ef-49c0-986e-3372b0c3f7c8",
   "metadata": {},
   "source": [
    "初步结论：\n",
    "\n",
    "- 还是有问题，无法处理中文\n",
    "- [[Bug]: BM25Retriever cannot work on chinese #13866](https://github.com/run-llama/llama_index/issues/13866)\n",
    "- [BM25Retriever 支持中文吗？](https://www.51cto.com/aigc/1003.html) - 这个文档给出的结果是可以用的，我的代码基本和他一样却不行"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35f5bb8-ae79-4f85-8b92-5b41f4272eec",
   "metadata": {},
   "source": [
    "## 准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "125fcc99-5a5d-4908-b5b5-c3fbba6e40b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16 ms, sys: 27.9 ms, total: 43.8 ms\n",
      "Wall time: 10.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%capture\n",
    "\n",
    "%pip install rank_bm25\n",
    "%pip install nltk jieba\n",
    "%pip install llama-index-retrievers-bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26d6797a-05bf-4a6c-a48e-3eeebe5f51e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 669 ms, sys: 186 ms, total: 855 ms\n",
      "Wall time: 1.2 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# 下载停用词\n",
    "\n",
    "# 设置 HTTP 代理环境变量\n",
    "# https://github.com/nltk/nltk_data/issues/154#issuecomment-2144880495\n",
    "http_proxy=\"http://192.168.0.134:7890\"\n",
    "\n",
    "import nltk\n",
    "nltk.set_proxy(f'{http_proxy}')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b38bef9e-a298-4867-805a-c2b721928fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11 µs, sys: 1 µs, total: 12 µs\n",
      "Wall time: 13.8 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import jieba\n",
    "from typing import List\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def chinese_tokenizer(text: str) -> List[str]:\n",
    "    # Use jieba to segment Chinese text\n",
    "    return list(jieba.cut(text))\n",
    "\n",
    "# def chinese_tokenizer(text: str) -> List[str]:\n",
    "#     tokens = jieba.lcut(text)\n",
    "#     return [token for token in tokens if token not in stopwords.words('chinese')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a20bdf-04c8-4720-8086-78f488f43782",
   "metadata": {},
   "source": [
    "## 简单测试 BM25 的使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4631afc2-1985-4279-9bf8-96e9e2cf0208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 339 µs, sys: 43 µs, total: 382 µs\n",
      "Wall time: 406 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.8621931, 0.       , 0.       , 0.       ])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "corpus = [\n",
    "    \"床前明月光\",\n",
    "    \"疑是地上霜\",\n",
    "    \"举头望明月\",\n",
    "    \"低头思故乡\",\n",
    "]\n",
    "tokenized_corpus = [chinese_tokenizer(doc) for doc in corpus]\n",
    "bm25 = BM25Okapi(tokenized_corpus)\n",
    "query = \"床前明月光\"\n",
    "tokenized_query = chinese_tokenizer(query)\n",
    "\n",
    "doc_scores = bm25.get_scores(tokenized_query)\n",
    "doc_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264e5a27-41d8-48fd-afbc-0b089f9da662",
   "metadata": {},
   "source": [
    "## llamaindex BM25Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "282e4cf5-b246-4a80-ab79-f753618a0b73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Node ID:** cd615693-be30-43e1-a69d-41bf74295fe1<br>**Similarity:** 0.0<br>**Text:** 低头思故乡<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 1cc4a96e-ba6c-4f28-bbd1-a04f438c21f0<br>**Similarity:** 0.0<br>**Text:** 举头望明月<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.01 ms, sys: 0 ns, total: 5.01 ms\n",
      "Wall time: 4.23 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from llama_index.retrievers.bm25 import BM25Retriever\n",
    "from llama_index.core import Document\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.response.notebook_utils import display_source_node\n",
    "\n",
    "documents = [Document(text=\"床前明月光\"),\n",
    "             Document(text=\"疑是地上霜\"),\n",
    "             Document(text=\"举头望明月\"),\n",
    "             Document(text=\"低头思故乡\")]\n",
    "\n",
    "splitter = SentenceSplitter(chunk_size=1024)\n",
    "nodes = splitter.get_nodes_from_documents(documents)\n",
    "\n",
    "retriever = BM25Retriever.from_defaults(\n",
    "    nodes=nodes,\n",
    "    similarity_top_k=2,\n",
    "    tokenizer=chinese_tokenizer\n",
    ")\n",
    "\n",
    "nodes = retriever.retrieve(\"故乡\")\n",
    "for node in nodes:\n",
    "    display_source_node(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c45808a-66fa-4ed8-8f66-166c57b7e2f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
