{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b0888a9-3987-486d-8d3b-c452799cb11c",
   "metadata": {},
   "source": [
    "# ChatTTS 最简示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ecd0a0d-5e2d-445f-be65-48ac8f70acd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.9 ms, sys: 5.82 ms, total: 16.7 ms\n",
      "Wall time: 3.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%capture\n",
    "\n",
    "%pip install ChatTTS omegaconf vocos vector_quantize_pytorch einops tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb923ffe-a07f-4ba9-8223-ef50c1bde59e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24 µs, sys: 5 µs, total: 29 µs\n",
      "Wall time: 31.5 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import torch\n",
    "torch._dynamo.config.cache_size_limit = 64\n",
    "torch._dynamo.config.suppress_errors = True\n",
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "import ChatTTS\n",
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ed7f4c36-ec54-4d50-9fda-ab27d2f9df5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17 µs, sys: 0 ns, total: 17 µs\n",
      "Wall time: 19.3 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import os\n",
    "\n",
    "# 设置HTTP代理环境变量\n",
    "os.environ['HTTP_PROXY'] = 'http://192.168.0.134:7890'\n",
    "os.environ['HTTPS_PROXY'] = 'http://192.168.0.134:7890'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a464cd48-230e-4bb6-b819-ce49f2f1ab2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:ChatTTS.core:use cuda:0\n",
      "WARNING:ChatTTS.core:vocos not initialized.\n",
      "WARNING:ChatTTS.core:gpt not initialized.\n",
      "WARNING:ChatTTS.core:tokenizer not initialized.\n",
      "WARNING:ChatTTS.core:dvae not initialized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.08 ms, sys: 46 µs, total: 4.12 ms\n",
      "Wall time: 3.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "chat = ChatTTS.Chat()\n",
    "chat.load_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b0ba572c-1ac3-4508-9025-6873fb1d184a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:ChatTTS.core:vocos not initialized.\n",
      "WARNING:ChatTTS.core:gpt not initialized.\n",
      "WARNING:ChatTTS.core:tokenizer not initialized.\n",
      "WARNING:ChatTTS.core:dvae not initialized.\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:4\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/ChatTTS/core.py:95\u001b[0m, in \u001b[0;36mChat.infer\u001b[0;34m(self, text, skip_refine_text, params_refine_text, params_infer_code, use_decoder)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minfer\u001b[39m(\u001b[38;5;28mself\u001b[39m, text, skip_refine_text\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, params_refine_text\u001b[38;5;241m=\u001b[39m{}, params_infer_code\u001b[38;5;241m=\u001b[39m{}, use_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m---> 95\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_model(use_decoder\u001b[38;5;241m=\u001b[39muse_decoder)\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m skip_refine_text:\n\u001b[1;32m     97\u001b[0m         text_tokens \u001b[38;5;241m=\u001b[39m refine_text(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpretrain_models, text, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams_refine_text)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mids\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "texts = [\"So we found being competitive and collaborative was a huge way of staying motivated towards our goals, so one person to call when you fall off, one person who gets you back on then one person to actually do the activity with.\",]*3 \\\n",
    "        + [\"我觉得像我们这些写程序的人，他，我觉得多多少少可能会对开源有一种情怀在吧我觉得开源是一个很好的形式。现在其实最先进的技术掌握在一些公司的手里的话，就他们并不会轻易的开放给所有的人用。\"]*3     \n",
    "        \n",
    "wavs = chat.infer(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3434da3b-0c6a-4f38-90a4-945afb706213",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
