{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1102283-2ed7-4dd8-852d-2cdf757da2c8",
   "metadata": {},
   "source": [
    "# Single-Turn Multi-Function Calling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cd3bb9-5b34-4afe-8033-09f8dcc8dead",
   "metadata": {},
   "source": [
    "目前只有openai支持。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd275b00-f243-431d-a420-95267c76a93e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.32 s, sys: 432 ms, total: 3.75 s\n",
      "Wall time: 3.37 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# 加载llm和embeddings\n",
    "%run ../utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48f6e4f7-bedf-4e23-9759-bd6b820d8edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6 µs, sys: 0 ns, total: 6 µs\n",
      "Wall time: 6.91 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from llama_index.core.tools import BaseTool, FunctionTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ced126db-bdd9-46ab-9606-18f6c025d6c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 699 µs, sys: 0 ns, total: 699 µs\n",
      "Wall time: 702 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiple two integers and returns the result integer\"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "multiply_tool = FunctionTool.from_defaults(fn=multiply)\n",
    "\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Add two integers and returns the result integer\"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "add_tool = FunctionTool.from_defaults(fn=add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "008c9cce-a4b2-4e8a-9d2c-370322cd4a93",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Model name qwen2-7b-6k does not support function calling API. ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:4\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/llama_index/agent/openai/base.py:119\u001b[0m, in \u001b[0;36mOpenAIAgent.from_tools\u001b[0;34m(cls, tools, tool_retriever, llm, chat_history, memory, memory_cls, verbose, max_function_calls, default_tool_choice, callback_manager, system_prompt, prefix_messages, tool_call_parser, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m memory \u001b[38;5;241m=\u001b[39m memory \u001b[38;5;129;01mor\u001b[39;00m memory_cls\u001b[38;5;241m.\u001b[39mfrom_defaults(chat_history, llm\u001b[38;5;241m=\u001b[39mllm)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m llm\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mis_function_calling_model:\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    120\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel name \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mllm\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not support function calling API. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    121\u001b[0m     )\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m system_prompt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m prefix_messages \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Model name qwen2-7b-6k does not support function calling API. "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# from llama_index.core.agent import ReActAgent\n",
    "from llama_index.agent.openai import OpenAIAgent\n",
    "\n",
    "agent = OpenAIAgent.from_tools(\n",
    "    [multiply_tool, add_tool], llm=llm, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52d1b526-ea35-4d0a-93a9-18638cccc67d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mThought: The current language of the user is: English. I need to use a tool to help me answer the question.\n",
      "Action: multiply\n",
      "Action Input: {'a': 121, 'b': 3}\n",
      "\u001b[0m\u001b[1;3;34mObservation: 363\n",
      "\u001b[0m\u001b[1;3;38;5;200mThought: (Implicit) I can answer without any more tools!\n",
      "Answer: Action: add\n",
      "Action Input: {'a': 363, 'b': 42}\n",
      "\u001b[0mAction: add\n",
      "Action Input: {'a': 363, 'b': 42}\n",
      "CPU times: user 68.2 ms, sys: 4.56 ms, total: 72.8 ms\n",
      "Wall time: 4.94 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "response = agent.chat(\"What is (121 * 3) + 42?\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcde034-84c0-45be-87c1-543edacae67b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
