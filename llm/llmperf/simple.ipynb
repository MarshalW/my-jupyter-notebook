{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebc052d4-efc6-4f08-b6dc-7b32e7b26b41",
   "metadata": {},
   "source": [
    "# LLMPerf 基本使用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941e935b-4a77-43d8-b114-1441ef236368",
   "metadata": {},
   "source": [
    "## 安装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1393701-9a06-4497-8460-473d242db5f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'llmperf'...\n",
      "remote: Enumerating objects: 159, done.\u001b[K\n",
      "remote: Counting objects: 100% (43/43), done.\u001b[K\n",
      "remote: Compressing objects: 100% (22/22), done.\u001b[K\n",
      "remote: Total 159 (delta 24), reused 21 (delta 20), pack-reused 116\u001b[K\n",
      "Receiving objects: 100% (159/159), 247.07 KiB | 634.00 KiB/s, done.\n",
      "Resolving deltas: 100% (76/76), done.\n",
      "/root/notebook/my-jupyter-notebook/llm/llmperf/llmperf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Obtaining file:///root/notebook/my-jupyter-notebook/llm/llmperf/llmperf\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hInstalling collected packages: UNKNOWN\n",
      "  Running setup.py develop for UNKNOWN\n",
      "Successfully installed UNKNOWN-0.0.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCPU times: user 140 ms, sys: 42.4 ms, total: 182 ms\n",
      "Wall time: 13.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# %%capture\n",
    "\n",
    "!rm -rf llmperf\n",
    "\n",
    "!export http_proxy=\"http://myproxy:7890\"\n",
    "!export https_proxy=\"http://myproxy:7890\"\n",
    "\n",
    "# 克隆仓库\n",
    "!git clone https://github.com/ray-project/llmperf.git\n",
    "\n",
    "# 进入仓库目录\n",
    "%cd llmperf\n",
    "\n",
    "!touch setup.cfg\n",
    "\n",
    "# 安装依赖\n",
    "!pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a92ebbee-af71-453a-aa71-cebd762a10be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 993 µs, sys: 8.05 ms, total: 9.04 ms\n",
      "Wall time: 266 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# https://huggingface.co/hf-internal-testing/llama-tokenizer/tree/main\n",
    "# 从下载的目录复制\n",
    "!mkdir hf-internal-testing\n",
    "!cp -r /models/llama-tokenizer hf-internal-testing\n",
    "# # 或者设置代理代码会自动下载\n",
    "# %env http_proxy=\"http:/myproxy:7890\"\n",
    "# %env https_proxy=\"http:/myproxy:7890\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a09fdc-dbc1-4fbd-b202-d4d6cb713817",
   "metadata": {},
   "source": [
    "## 负载测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e207414a-1e26-4f9d-a242-f2e334e23eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: OPENAI_API_KEY=ollama\n",
      "env: OPENAI_API_BASE=http://monkey:11434/v1\n",
      "2024-07-29 12:13:21,769\tINFO worker.py:1781 -- Started a local Ray instance.\n",
      "100%|███████████████████████████████████████████| 15/15 [00:46<00:00,  3.08s/it]\n",
      "\\Results for token benchmark for qwen2 queried with the openai api.\n",
      "\n",
      "inter_token_latency_s\n",
      "    p25 = 0.01603434762869469\n",
      "    p50 = 0.016938249485479444\n",
      "    p75 = 0.017360754820353003\n",
      "    p90 = 0.017876612636572486\n",
      "    p95 = 0.018971393072495717\n",
      "    p99 = 0.020847692224311057\n",
      "    mean = 0.016964522223046577\n",
      "    min = 0.015309175025475652\n",
      "    max = 0.021316767012264894\n",
      "    stddev = 0.0014337638281852938\n",
      "ttft_s\n",
      "    p25 = 0.29546627099625766\n",
      "    p50 = 0.31401156866922975\n",
      "    p75 = 0.32579391822218895\n",
      "    p90 = 0.43683249326422807\n",
      "    p95 = 0.7342840123455961\n",
      "    p99 = 1.2668551070149983\n",
      "    mean = 0.3933897516069313\n",
      "    min = 0.2623775019310415\n",
      "    max = 1.3999978806823492\n",
      "    stddev = 0.28290392637399286\n",
      "end_to_end_latency_s\n",
      "    p25 = 2.804130371194333\n",
      "    p50 = 2.9222257849760354\n",
      "    p75 = 3.0765876942314208\n",
      "    p90 = 3.225854839850217\n",
      "    p95 = 3.550245002750306\n",
      "    p99 = 4.137943798843771\n",
      "    mean = 3.032359540152053\n",
      "    min = 2.6771028651855886\n",
      "    max = 4.284868497867137\n",
      "    stddev = 0.38335910386700933\n",
      "request_output_throughput_token_per_s\n",
      "    p25 = 57.60454205982147\n",
      "    p50 = 59.03431551725104\n",
      "    p75 = 62.36299394849965\n",
      "    p90 = 63.11758851977723\n",
      "    p95 = 63.91052253314845\n",
      "    p99 = 65.03540372993885\n",
      "    mean = 59.29048619893423\n",
      "    min = 46.90925756532575\n",
      "    max = 65.31662402913645\n",
      "    stddev = 4.431097871026905\n",
      "number_input_tokens\n",
      "    p25 = 493.5\n",
      "    p50 = 538.0\n",
      "    p75 = 591.0\n",
      "    p90 = 843.8\n",
      "    p95 = 987.6999999999999\n",
      "    p99 = 1026.34\n",
      "    mean = 585.4\n",
      "    min = 354\n",
      "    max = 1036\n",
      "    stddev = 184.75265318025302\n",
      "number_output_tokens\n",
      "    p25 = 172.0\n",
      "    p50 = 181.0\n",
      "    p75 = 188.5\n",
      "    p90 = 190.6\n",
      "    p95 = 194.0\n",
      "    p99 = 199.6\n",
      "    mean = 178.66666666666666\n",
      "    min = 149\n",
      "    max = 201\n",
      "    stddev = 13.803036242936175\n",
      "Number Of Errored Requests: 0\n",
      "Overall Output Throughput: 58.07299365297813\n",
      "Number Of Completed Requests: 15\n",
      "Completed Requests Per Minute: 19.502124734209072\n",
      "\u001b[0mCPU times: user 494 ms, sys: 57.9 ms, total: 552 ms\n",
      "Wall time: 52.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# 设置环境变量\n",
    "%env OPENAI_API_KEY=ollama\n",
    "%env OPENAI_API_BASE=http://monkey:11434/v1\n",
    "\n",
    "# !python3 token_benchmark_ray.py \\\n",
    "!PYTHONPATH=$(pwd)/src python3 token_benchmark_ray.py \\\n",
    "--model \"qwen2\" \\\n",
    "--mean-input-tokens 550 \\\n",
    "--stddev-input-tokens 150 \\\n",
    "--mean-output-tokens 150 \\\n",
    "--stddev-output-tokens 10 \\\n",
    "--max-num-completed-requests 15 \\\n",
    "--timeout 600 \\\n",
    "--num-concurrent-requests 1 \\\n",
    "--results-dir \"result_outputs\" \\\n",
    "--llm-api openai \\\n",
    "--additional-sampling-params '{}'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7427d58b-fa38-45f2-88e1-9cc01f71faf1",
   "metadata": {},
   "source": [
    "## 正确性测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25d1df4f-180f-4945-afb8-72f59ad6df8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: OPENAI_API_KEY=ollama\n",
      "env: OPENAI_API_BASE=http://monkey:11434/v1\n",
      "2024-07-29 11:35:06,702\tINFO worker.py:1781 -- Started a local Ray instance.\n",
      "100%|█████████████████████████████████████████| 150/150 [00:11<00:00, 13.35it/s]\n",
      "Mismatched and errored requests.\n",
      "    mismatched request: 8800, expected: 8880\n",
      "\n",
      "Results for llm correctness test for qwen2 queried with the openai api.\n",
      "Errors: 0, Error rate: 0.0\n",
      "Mismatched: 1, Mismatch rate: 0.006666666666666667\n",
      "Completed: 150\n",
      "Completed without errors: 150\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# 设置环境变量\n",
    "%env OPENAI_API_KEY=ollama\n",
    "%env OPENAI_API_BASE=http://monkey:11434/v1\n",
    "\n",
    "!PYTHONPATH=$(pwd)/src python3 llm_correctness.py \\\n",
    "--model \"qwen2\" \\\n",
    "--max-num-completed-requests 150 \\\n",
    "--timeout 600 \\\n",
    "--num-concurrent-requests 10 \\\n",
    "--results-dir \"result_outputs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba089631-8226-48c7-b3ab-cec1ba8ad567",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
