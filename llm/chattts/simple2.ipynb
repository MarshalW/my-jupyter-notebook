{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ac4b283-a80d-4d60-a256-79928b2abdf8",
   "metadata": {},
   "source": [
    "# 适合国内环境的最简示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54e37b70-d5d3-4efd-9e16-34df8cb61986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.71 ms, sys: 14.2 ms, total: 21.9 ms\n",
      "Wall time: 3.78 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%capture\n",
    "\n",
    "%pip install modelscope ChatTTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7d1b598-964d-4c8e-9225-3a5dd303db15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-11 22:05:26,416 - modelscope - INFO - PyTorch version 2.3.0 Found.\n",
      "2024-06-11 22:05:26,418 - modelscope - INFO - Loading ast index from /root/.cache/modelscope/ast_indexer\n",
      "2024-06-11 22:05:26,418 - modelscope - INFO - No valid ast index found from /root/.cache/modelscope/ast_indexer, generating ast index from prebuilt!\n",
      "2024-06-11 22:05:26,457 - modelscope - INFO - Loading done! Current index file version is 1.15.0, with md5 0e1b53bb46117be05b5c08358fc0fd55 and a total number of 980 components indexed\n",
      "Downloading: 100% 47.0/47.0 [00:00<00:00, 254B/s]\n",
      "Downloading: 100% 98.9M/98.9M [00:09<00:00, 11.3MB/s]\n",
      "Downloading: 100% 117/117 [00:00<00:00, 612B/s]\n",
      "Downloading: 100% 26.5M/26.5M [00:02<00:00, 9.83MB/s]\n",
      "Downloading: 100% 143/143 [00:00<00:00, 509B/s]\n",
      "Downloading: 100% 859M/859M [01:17<00:00, 11.6MB/s] \n",
      "Downloading: 100% 346/346 [00:00<00:00, 1.75kB/s]\n",
      "Downloading: 100% 309/309 [00:00<00:00, 840B/s]\n",
      "Downloading: 100% 1.36k/1.36k [00:00<00:00, 7.42kB/s]\n",
      "Downloading: 100% 4.16k/4.16k [00:00<00:00, 20.8kB/s]\n",
      "Downloading: 100% 329k/329k [00:00<00:00, 1.31MB/s]\n",
      "Downloading: 100% 51.8M/51.8M [00:04<00:00, 11.1MB/s]\n",
      "Downloading: 100% 460/460 [00:00<00:00, 2.37kB/s]\n"
     ]
    }
   ],
   "source": [
    "#SDK模型下载\n",
    "from modelscope import snapshot_download\n",
    "model_dir = snapshot_download('pzc163/chatTTS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ac7e787-115d-4a0b-839a-e2c1e14b233e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 40 µs, sys: 0 ns, total: 40 µs\n",
      "Wall time: 42.2 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import torch\n",
    "torch._dynamo.config.cache_size_limit = 64\n",
    "torch._dynamo.config.suppress_errors = True\n",
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "import ChatTTS\n",
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7c21a3f-511a-47ea-9a03-3775de4f3b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'chatTTS'...\n",
      "remote: Enumerating objects: 49, done.\u001b[K\n",
      "remote: Counting objects: 100% (49/49), done.\u001b[K\n",
      "remote: Compressing objects: 100% (39/39), done.\u001b[K\n",
      "remote: Total 49 (delta 15), reused 29 (delta 8), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (49/49), 6.23 KiB | 6.23 MiB/s, done.\n",
      "Resolving deltas: 100% (15/15), done.\n",
      "Filtering content: 100% (6/6), 1.01 GiB | 10.80 MiB/s, done.\n"
     ]
    }
   ],
   "source": [
    "#Git模型下载\n",
    "!git clone https://www.modelscope.cn/pzc163/chatTTS.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f21ddbb-626f-4758-a69d-6eeb635606b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Chat.load_models() got an unexpected keyword argument 'source'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m chat \u001b[38;5;241m=\u001b[39m ChatTTS\u001b[38;5;241m.\u001b[39mChat()\n\u001b[0;32m----> 2\u001b[0m \u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlocal\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/root/notebook/my-jupyter-notebook/llm/chattts/chatTTS/asset\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: Chat.load_models() got an unexpected keyword argument 'source'"
     ]
    }
   ],
   "source": [
    "chat = ChatTTS.Chat()\n",
    "chat.load_models(source='local', local_path='/root/notebook/my-jupyter-notebook/llm/chattts/chatTTS/asset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "09f18486-e679-41d9-a95b-131b8a6ef3b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:ChatTTS.core:vocos not initialized.\n",
      "WARNING:ChatTTS.core:gpt not initialized.\n",
      "WARNING:ChatTTS.core:tokenizer not initialized.\n",
      "WARNING:ChatTTS.core:dvae not initialized.\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m texts \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSo we found being competitive and collaborative was a huge way of staying motivated towards our goals, so one person to call when you fall off, one person who gets you back on then one person to actually do the activity with.\u001b[39m\u001b[38;5;124m\"\u001b[39m,]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m3\u001b[39m \\\n\u001b[1;32m      2\u001b[0m         \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m我觉得像我们这些写程序的人，他，我觉得多多少少可能会对开源有一种情怀在吧我觉得开源是一个很好的形式。现在其实最先进的技术掌握在一些公司的手里的话，就他们并不会轻易的开放给所有的人用。\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m3\u001b[39m     \n\u001b[0;32m----> 4\u001b[0m wavs \u001b[38;5;241m=\u001b[39m \u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/ChatTTS/core.py:95\u001b[0m, in \u001b[0;36mChat.infer\u001b[0;34m(self, text, skip_refine_text, params_refine_text, params_infer_code, use_decoder)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minfer\u001b[39m(\u001b[38;5;28mself\u001b[39m, text, skip_refine_text\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, params_refine_text\u001b[38;5;241m=\u001b[39m{}, params_infer_code\u001b[38;5;241m=\u001b[39m{}, use_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m---> 95\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_model(use_decoder\u001b[38;5;241m=\u001b[39muse_decoder)\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m skip_refine_text:\n\u001b[1;32m     97\u001b[0m         text_tokens \u001b[38;5;241m=\u001b[39m refine_text(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpretrain_models, text, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams_refine_text)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mids\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "texts = [\"So we found being competitive and collaborative was a huge way of staying motivated towards our goals, so one person to call when you fall off, one person who gets you back on then one person to actually do the activity with.\",]*3 \\\n",
    "        + [\"我觉得像我们这些写程序的人，他，我觉得多多少少可能会对开源有一种情怀在吧我觉得开源是一个很好的形式。现在其实最先进的技术掌握在一些公司的手里的话，就他们并不会轻易的开放给所有的人用。\"]*3     \n",
    "        \n",
    "wavs = chat.infer(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30328e4-4a60-4133-9dbb-a7ec12717735",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
