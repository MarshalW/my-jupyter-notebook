{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5eff1fea-3c9a-4f08-a4ec-06bf245453b7",
   "metadata": {},
   "source": [
    "https://github.com/truera/trulens/blob/main/trulens_eval/examples/expositional/models/litellm_quickstart.ipynb\n",
    "\n",
    "结论：\n",
    "\n",
    "- 使用litellm定制后，虽然还是openai，但是终于能得到评估结果了\n",
    "- 初步认为，是TruLens代码中的bug，还在默认使用openai的设置，造成连接错误\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d1b4fbe-e861-4021-b486-c011baf40933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9 µs, sys: 2 µs, total: 11 µs\n",
      "Wall time: 12.6 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import os\n",
    "\n",
    "base_url = \"http://ape:3000/v1\"\n",
    "api_key = \"sk-bJP6QSnUfjAYeYeE505d3eBf63A643BeB0B8E350Df9b7750\"\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "os.environ[\"OPENAI_API_BASE\"] = base_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "353315d0-41f6-4823-ba53-3587eefb0e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "university_info = \"\"\"\n",
    "The University of Washington, founded in 1861 in Seattle, is a public research university\n",
    "with over 45,000 students across three campuses in Seattle, Tacoma, and Bothell.\n",
    "As the flagship institution of the six public universities in Washington state,\n",
    "UW encompasses over 500 buildings and 20 million square feet of space,\n",
    "including one of the largest library systems in the world.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "871f0a7a-2d41-4717-85c0-bd28fd0e01ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef9432f6-e32b-4c42-b66c-5ab843300a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 880 ms, sys: 175 ms, total: 1.06 s\n",
      "Wall time: 863 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from chromadb.utils.embedding_functions import OpenAIEmbeddingFunction\n",
    "\n",
    "embedding_function = OpenAIEmbeddingFunction(\n",
    "    api_key=api_key,\n",
    "    model_name=\"text-embedding-ada-002\",\n",
    "    api_base=base_url,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f9ed0e4-fe89-4ad7-ab56-74f70178fdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "\n",
    "chroma_client = chromadb.Client()\n",
    "vector_store = chroma_client.get_or_create_collection(\n",
    "    name=\"Universities\",\n",
    "    embedding_function=embedding_function\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "646c901d-d07b-4859-8db2-a83228fc1107",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store.add(\n",
    "    \"uni_info\",\n",
    "    documents=university_info,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e420a093-bfec-4f99-9e4c-6429f418a1a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦑 Tru initialized with db url sqlite:///default.sqlite .\n",
      "🛑 Secret keys may be written to the database. See the `database_redact_keys` option of `Tru` to prevent this.\n",
      "CPU times: user 6.04 s, sys: 411 ms, total: 6.45 s\n",
      "Wall time: 6.29 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from trulens_eval import Tru\n",
    "from trulens_eval.tru_custom_app import instrument\n",
    "\n",
    "tru = Tru()\n",
    "tru.reset_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d65006a5-3875-4e39-bc89-f955a62cd2ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 41 µs, sys: 3 µs, total: 44 µs\n",
      "Wall time: 46.3 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import litellm\n",
    "from litellm import embedding\n",
    "\n",
    "\n",
    "class RAG_from_scratch:\n",
    "    @instrument\n",
    "    def retrieve(self, query: str) -> list:\n",
    "        \"\"\"\n",
    "        Retrieve relevant text from vector store.\n",
    "        \"\"\"\n",
    "        results = vector_store.query(\n",
    "            query_embeddings=embedding(\n",
    "                model=\"text-embedding-ada-002\", \n",
    "                input=query\n",
    "            ).data[0][\"embedding\"],\n",
    "            n_results=2,\n",
    "        )\n",
    "        return results[\"documents\"]\n",
    "\n",
    "    @instrument\n",
    "    def generate_completion(self, query: str, context_str: list) -> str:\n",
    "        \"\"\"\n",
    "        Generate answer from context.\n",
    "        \"\"\"\n",
    "        completion = (\n",
    "            litellm.completion(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                api_base=base_url,\n",
    "                temperature=0,\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": f\"We have provided context information below. \\n\"\n",
    "                        f\"---------------------\\n\"\n",
    "                        f\"{context_str}\"\n",
    "                        f\"\\n---------------------\\n\"\n",
    "                        f\"Given this information, please answer the question: {query}\",\n",
    "                    }\n",
    "                ],\n",
    "            )\n",
    "            .choices[0]\n",
    "            .message.content\n",
    "        )\n",
    "        return completion\n",
    "\n",
    "    @instrument\n",
    "    def query(self, query: str) -> str:\n",
    "        context_str = self.retrieve(query)\n",
    "        completion = self.generate_completion(query, context_str)\n",
    "        return completion\n",
    "\n",
    "\n",
    "rag = RAG_from_scratch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95caf554-2841-4ab3-9c68-2bdb9e921479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ In Groundedness, input source will be set to __record__.app.retrieve.rets.collect() .\n",
      "✅ In Groundedness, input statement will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "✅ In Answer Relevance, input prompt will be set to __record__.app.retrieve.args.query .\n",
      "✅ In Answer Relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "✅ In Context Relevance, input question will be set to __record__.app.retrieve.args.query .\n",
      "✅ In Context Relevance, input context will be set to __record__.app.retrieve.rets.collect() .\n",
      "✅ In coherence, input text will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "CPU times: user 84.3 ms, sys: 31 µs, total: 84.3 ms\n",
      "Wall time: 83.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from trulens_eval import Feedback\n",
    "from trulens_eval import LiteLLM\n",
    "from trulens_eval import Select\n",
    "\n",
    "# Initialize LiteLLM-based feedback function collection class:\n",
    "provider = LiteLLM(\n",
    "    model_engine=\"gpt-3.5-turbo\",\n",
    "    # api_base=\"http://monkey:11434\",\n",
    "    # api_key =api_key,\n",
    ")\n",
    "\n",
    "# Define a groundedness feedback function\n",
    "f_groundedness = (\n",
    "    Feedback(\n",
    "        provider.groundedness_measure_with_cot_reasons, name=\"Groundedness\"\n",
    "    )\n",
    "    .on(Select.RecordCalls.retrieve.rets.collect())\n",
    "    .on_output()\n",
    ")\n",
    "\n",
    "# Question/answer relevance between overall question and answer.\n",
    "f_answer_relevance = (\n",
    "    Feedback(provider.relevance_with_cot_reasons, name=\"Answer Relevance\")\n",
    "    .on(Select.RecordCalls.retrieve.args.query)\n",
    "    .on_output()\n",
    ")\n",
    "\n",
    "# Question/statement relevance between question and each context chunk.\n",
    "f_context_relevance = (\n",
    "    Feedback(\n",
    "        provider.context_relevance_with_cot_reasons, name=\"Context Relevance\"\n",
    "    )\n",
    "    .on(Select.RecordCalls.retrieve.args.query)\n",
    "    .on(Select.RecordCalls.retrieve.rets.collect())\n",
    "    .aggregate(np.mean)\n",
    ")\n",
    "\n",
    "f_coherence = Feedback(\n",
    "    provider.coherence_with_cot_reasons, name=\"coherence\"\n",
    ").on_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a88d5532-c1da-40ce-a7de-5a3865672f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval import TruCustomApp\n",
    "\n",
    "tru_rag = TruCustomApp(\n",
    "    rag,\n",
    "    app_id=\"RAG v1\",\n",
    "    feedbacks=[\n",
    "        f_groundedness,\n",
    "        f_answer_relevance,\n",
    "        f_context_relevance,\n",
    "        f_coherence,\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0581707-2ece-488b-8ecc-7e21d2277719",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# [nltk_data] Error loading punkt: <urlopen error [Errno 111] Connection\n",
    "nltk.set_proxy('http://myproxy:7890')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "038d237f-ca9c-4509-8ddb-ba870962331c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tru_rag as recording:\n",
    "    rag.query(\"Give me a long history of U Dub\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "896d3d71-8e59-4970-92cc-6425ccdd445e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Answer Relevance</th>\n",
       "      <th>Context Relevance</th>\n",
       "      <th>Groundedness</th>\n",
       "      <th>coherence</th>\n",
       "      <th>latency</th>\n",
       "      <th>total_cost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>app_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RAG v1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.612222</td>\n",
       "      <td>0.9</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.000619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Answer Relevance  Context Relevance  Groundedness  coherence  latency  \\\n",
       "app_id                                                                          \n",
       "RAG v1               1.0               0.75      0.612222        0.9      6.0   \n",
       "\n",
       "        total_cost  \n",
       "app_id              \n",
       "RAG v1    0.000619  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tru.get_leaderboard(app_ids=[\"RAG v1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b4f0ee-3a28-41bd-9ccd-39e675c21b41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
