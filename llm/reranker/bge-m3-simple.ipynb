{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7301cb10-cf29-492a-824a-db381df4ee3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 48.7 ms, sys: 8 ms, total: 56.7 ms\n",
      "Wall time: 9.77 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%capture\n",
    "\n",
    "!pip install langchain\n",
    "!pip install langchain-openai\n",
    "!pip install faiss-gpu\n",
    "!pip install sentence_transformers\n",
    "!pip install openai\n",
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e60e95e-efce-4157-8453-3447c855242b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 44.8 ms, sys: 1.76 ms, total: 46.6 ms\n",
      "Wall time: 45.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain_core.vectorstores import VectorStoreRetriever\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "from langchain_core.vectorstores import VectorStoreRetriever\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "%load_ext dotenv\n",
    "%dotenv\n",
    "\n",
    "token = os.environ.get('ONE_API_TOKEN')\n",
    "base_url=os.environ.get('ONE_API_URL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa9b7681-f49e-4994-b5bd-ec5f81ee1ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.01 s, sys: 1.05 s, total: 4.06 s\n",
      "Wall time: 3.17 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_name='/models/bge-m3'\n",
    "model_kwargs = {\"device\": \"cuda\"}\n",
    "encode_kwargs = {\"normalize_embeddings\": True}\n",
    "embeddings = HuggingFaceBgeEmbeddings(\n",
    "    model_name=model_name, model_kwargs=model_kwargs, encode_kwargs=encode_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11b41dc9-f605-413a-8755-d2ae30bded76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 820 µs, sys: 0 ns, total: 820 µs\n",
      "Wall time: 834 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%capture\n",
    "\n",
    "documents=[]\n",
    "loader = TextLoader(\"./孔乙己.txt\")\n",
    "documents.extend(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b691fe14-7e64-4713-a064-a367b777a50d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.62 ms, sys: 0 ns, total: 4.62 ms\n",
      "Wall time: 4.31 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter=RecursiveCharacterTextSplitter(chunk_size=128,chunk_overlap=20)\n",
    "text_splits=text_splitter.split_documents(documents)\n",
    "\n",
    "len(text_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f7b8a67-2404-4abb-8e57-e8c7eb2e1b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 758 ms, sys: 60.5 ms, total: 819 ms\n",
      "Wall time: 816 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "vectorstore = FAISS.from_documents(text_splits, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aadb14e3-70a7-4e9e-8617-8ac1327a79e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 91.6 ms, sys: 1.76 ms, total: 93.3 ms\n",
      "Wall time: 92.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "chat = ChatOpenAI(api_key=token, \n",
    "                  base_url=base_url,\n",
    "                  model='xiaoyu', \n",
    "                  temperature=0,\n",
    "                  streaming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5a98d7ae-1a04-4a2d-acbe-775ec5b34b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 297 µs, sys: 0 ns, total: 297 µs\n",
      "Wall time: 301 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from langchain_core.vectorstores import VectorStoreRetriever\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "\n",
    "retriever = VectorStoreRetriever(vectorstore=vectorstore,search_kwargs={\"k\": 10})\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=chat, retriever=retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e368c5dd-58ba-4df8-b582-c699f30c48ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 422 µs, sys: 0 ns, total: 422 µs\n",
      "Wall time: 427 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains import create_retrieval_chain\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"Answer the following question based only on the provided context:\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Question: {input}\"\"\")\n",
    "\n",
    "document_chain = create_stuff_documents_chain(chat, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "930c1ba8-667a-49a7-adc3-288bb895e2d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 473 µs, sys: 0 ns, total: 473 µs\n",
      "Wall time: 477 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 10,\"score_threshold\": 0.4},search_type=\"similarity_score_threshold\")\n",
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fe769fee-215d-4a31-a945-4dbca891793d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.49 s, sys: 555 ms, total: 2.04 s\n",
      "Wall time: 1.09 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from bge_rerank import BgeRerank\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "\n",
    "compressor = BgeRerank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b82d493c-8f64-4329-ad3d-949aacbfea91",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BgeRerank' object has no attribute 'with_config'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:1\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/retrieval.py:65\u001b[0m, in \u001b[0;36mcreate_retrieval_chain\u001b[0;34m(retriever, combine_docs_chain)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     61\u001b[0m     retrieval_docs \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m|\u001b[39m retriever\n\u001b[1;32m     63\u001b[0m retrieval_chain \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     64\u001b[0m     RunnablePassthrough\u001b[38;5;241m.\u001b[39massign(\n\u001b[0;32m---> 65\u001b[0m         context\u001b[38;5;241m=\u001b[39m\u001b[43mretrieval_docs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwith_config\u001b[49m(run_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mretrieve_documents\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     66\u001b[0m     )\u001b[38;5;241m.\u001b[39massign(answer\u001b[38;5;241m=\u001b[39mcombine_docs_chain)\n\u001b[1;32m     67\u001b[0m )\u001b[38;5;241m.\u001b[39mwith_config(run_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mretrieval_chain\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retrieval_chain\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'BgeRerank' object has no attribute 'with_config'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "retrieval_chain = create_retrieval_chain(compressor, retrieval_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51e64ee-1477-4030-9791-d9d32fe702e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
