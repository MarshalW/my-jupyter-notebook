{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "374c0d93-5c0b-4a7f-85df-06b01b23f548",
   "metadata": {},
   "source": [
    "# Qdrant memory 能否加载索引"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360e8724-529c-4a19-b57c-ae091fb38171",
   "metadata": {},
   "source": [
    "证明了：\n",
    "\n",
    "- 嵌入是保存在向量数据库中的"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f1d625-81c7-4048-b346-10c20804db26",
   "metadata": {},
   "source": [
    "## 准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34e7514d-3d30-452a-9679-c54b2fc124e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.95 s, sys: 512 ms, total: 4.47 s\n",
      "Wall time: 4.15 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "persist_dir = \"/tmp/qdrant_my_books\"\n",
    "collection_name=\"my_books\"\n",
    "\n",
    "from llama_index.embeddings.fastembed import FastEmbedEmbedding\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core import Settings\n",
    "\n",
    "Settings.embed_model = HuggingFaceEmbedding(model_name=\"/models/bge-small-zh-v1.5\")\n",
    "Settings.embed_model.max_length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ea7caf-1d68-4f47-920b-2e32971dd2d8",
   "metadata": {},
   "source": [
    "## 加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd35e648-fc9c-4f08-930d-4fa1ea5fed48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 744 ms, sys: 8.05 ms, total: 752 ms\n",
      "Wall time: 751 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client import models\n",
    "\n",
    "client = QdrantClient(\":memory:\")\n",
    "\n",
    "\n",
    "if not client.collection_exists(collection_name):\n",
    "    client.create_collection(\n",
    "        collection_name=collection_name,\n",
    "        vectors_config=models.VectorParams(\n",
    "            size=Settings.embed_model.max_length,\n",
    "            distance=models.Distance.COSINE,\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30a3111c-af51-494f-9785-3856bc89e6fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 122 ms, sys: 11.5 ms, total: 134 ms\n",
      "Wall time: 134 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from llama_index.core import StorageContext\n",
    "from llama_index.core import load_index_from_storage\n",
    "from llama_index.vector_stores.qdrant import QdrantVectorStore\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from qdrant_client import models\n",
    "\n",
    "vector_store = QdrantVectorStore(\n",
    "    client=client, \n",
    "    collection_name=collection_name,\n",
    "    vectors_config=models.VectorParams(\n",
    "        size=Settings.embed_model.max_length,\n",
    "        distance=models.Distance.COSINE,\n",
    "    ),\n",
    ")\n",
    "\n",
    "storage_context = StorageContext.from_defaults(\n",
    "    vector_store=vector_store,\n",
    "    persist_dir=persist_dir\n",
    ")\n",
    "index = load_index_from_storage(storage_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d23877-4fdd-4266-b7e5-cf1e867e5e62",
   "metadata": {},
   "source": [
    "## 查询 - 无结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc11b617-2e2d-4a7f-9183-d0b3cf5b8c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 394 ms, sys: 44 ms, total: 438 ms\n",
      "Wall time: 437 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "retriever = index.as_retriever()\n",
    "nodes = retriever.retrieve(\"方鸿渐\")\n",
    "\n",
    "nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27ec311-a81d-482b-b58f-392dcfab5e1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
