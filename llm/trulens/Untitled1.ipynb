{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eee00177-eb24-4438-ab94-afe1e5c047b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring additional kwargs for singleton endpoint litellm: {'api_base': 'http://192.168.0.73:11434'}\n",
      "Singleton instance of type LiteLLMEndpoint already created at:\n",
      "/tmp/ipykernel_5121/419099346.py:5\n",
      "\tollama_provider = LiteLLM(\n",
      "\n",
      "You can delete the singleton by calling `<instance>.delete_singleton()` or \n",
      "  ```python\n",
      "  from trulens_eval.utils.python import SingletonPerName\n",
      "  SingletonPerName.delete_singleton_by_name(name=\"litellm\", cls=LiteLLMEndpoint)\n",
      "  ```\n",
      "            \n",
      "litellm request failed <class 'litellm.exceptions.ServiceUnavailableError'>=litellm.ServiceUnavailableError: OllamaException: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f0312de17b0>: Failed to establish a new connection: [Errno 111] Connection refused')). Retries remaining=3.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ In relevance_with_cot_reasons, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "✅ In relevance_with_cot_reasons, input response will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "litellm request failed <class 'litellm.exceptions.ServiceUnavailableError'>=litellm.ServiceUnavailableError: OllamaException: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f0312dfa980>: Failed to establish a new connection: [Errno 111] Connection refused')). Retries remaining=2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "litellm request failed <class 'litellm.exceptions.ServiceUnavailableError'>=litellm.ServiceUnavailableError: OllamaException: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f0312dfb460>: Failed to establish a new connection: [Errno 111] Connection refused')). Retries remaining=1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "litellm request failed <class 'litellm.exceptions.ServiceUnavailableError'>=litellm.ServiceUnavailableError: OllamaException: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f0312e00100>: Failed to establish a new connection: [Errno 111] Connection refused')). Retries remaining=0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Endpoint litellm request failed 4 time(s): \n\tlitellm.ServiceUnavailableError: OllamaException: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f0312de17b0>: Failed to establish a new connection: [Errno 111] Connection refused'))\n\tlitellm.ServiceUnavailableError: OllamaException: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f0312dfa980>: Failed to establish a new connection: [Errno 111] Connection refused'))\n\tlitellm.ServiceUnavailableError: OllamaException: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f0312dfb460>: Failed to establish a new connection: [Errno 111] Connection refused'))\n\tlitellm.ServiceUnavailableError: OllamaException: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f0312e00100>: Failed to establish a new connection: [Errno 111] Connection refused'))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Define a relevance function using LiteLLM\u001b[39;00m\n\u001b[1;32m     10\u001b[0m relevance \u001b[38;5;241m=\u001b[39m Feedback(ollama_provider\u001b[38;5;241m.\u001b[39mrelevance_with_cot_reasons)\u001b[38;5;241m.\u001b[39mon_input_output()\n\u001b[0;32m---> 12\u001b[0m \u001b[43mollama_provider\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelevance_with_cot_reasons\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWhat is a good name for a store that sells colorful socks?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGreat question! Naming a store that sells colorful socks can be a fun and creative process. Here are some suggestions to consider: SoleMates: This name plays on the idea of socks being your soul mate or partner in crime for the day. It is catchy and easy to remember, and it conveys the idea that the store offers a wide variety of sock styles and colors.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/trulens_eval/feedback/provider/base.py:436\u001b[0m, in \u001b[0;36mLLMProvider.relevance_with_cot_reasons\u001b[0;34m(self, prompt, response)\u001b[0m\n\u001b[1;32m    430\u001b[0m user_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    431\u001b[0m     prompts\u001b[38;5;241m.\u001b[39mANSWER_RELEVANCE_USER, prompt\u001b[38;5;241m=\u001b[39mprompt, response\u001b[38;5;241m=\u001b[39mresponse\n\u001b[1;32m    432\u001b[0m )\n\u001b[1;32m    433\u001b[0m user_prompt \u001b[38;5;241m=\u001b[39m user_prompt\u001b[38;5;241m.\u001b[39mreplace(\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRELEVANCE:\u001b[39m\u001b[38;5;124m\"\u001b[39m, prompts\u001b[38;5;241m.\u001b[39mCOT_REASONS_TEMPLATE\n\u001b[1;32m    435\u001b[0m )\n\u001b[0;32m--> 436\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_score_and_reasons\u001b[49m\u001b[43m(\u001b[49m\u001b[43msystem_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_prompt\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/trulens_eval/feedback/provider/base.py:198\u001b[0m, in \u001b[0;36mLLMProvider.generate_score_and_reasons\u001b[0;34m(self, system_prompt, user_prompt, normalize, temperature)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m user_prompt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    197\u001b[0m     llm_messages\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: user_prompt})\n\u001b[0;32m--> 198\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_in_pace\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_chat_completion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mllm_messages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemperature\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSupporting Evidence\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m response:\n\u001b[1;32m    204\u001b[0m     score \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/trulens_eval/feedback/provider/endpoint/base.py:313\u001b[0m, in \u001b[0;36mEndpoint.run_in_pace\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    310\u001b[0m             sleep(retry_delay)\n\u001b[1;32m    311\u001b[0m             retry_delay \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m--> 313\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEndpoint \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m request failed \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretries\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m time(s): \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;241m+\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mstr\u001b[39m, errors)))\n\u001b[1;32m    316\u001b[0m )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Endpoint litellm request failed 4 time(s): \n\tlitellm.ServiceUnavailableError: OllamaException: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f0312de17b0>: Failed to establish a new connection: [Errno 111] Connection refused'))\n\tlitellm.ServiceUnavailableError: OllamaException: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f0312dfa980>: Failed to establish a new connection: [Errno 111] Connection refused'))\n\tlitellm.ServiceUnavailableError: OllamaException: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f0312dfb460>: Failed to establish a new connection: [Errno 111] Connection refused'))\n\tlitellm.ServiceUnavailableError: OllamaException: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f0312e00100>: Failed to establish a new connection: [Errno 111] Connection refused'))"
     ]
    }
   ],
   "source": [
    "from trulens_eval.feedback.provider import LiteLLM\n",
    "import litellm\n",
    "from trulens_eval import Feedback\n",
    "\n",
    "ollama_provider = LiteLLM(\n",
    "    model_engine=\"ollama/qwen2\", \n",
    "    api_base=\"http://192.168.0.73:11434\")\n",
    "\n",
    "# Define a relevance function using LiteLLM\n",
    "relevance = Feedback(ollama_provider.relevance_with_cot_reasons).on_input_output()\n",
    "\n",
    "ollama_provider.relevance_with_cot_reasons(\"What is a good name for a store that sells colorful socks?\", \"Great question! Naming a store that sells colorful socks can be a fun and creative process. Here are some suggestions to consider: SoleMates: This name plays on the idea of socks being your soul mate or partner in crime for the day. It is catchy and easy to remember, and it conveys the idea that the store offers a wide variety of sock styles and colors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0117df5-d1cf-4c31-a468-0b16ba70ff8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
