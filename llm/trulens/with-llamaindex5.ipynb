{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c7f3543-388e-4ffd-a67f-09e3e905f4da",
   "metadata": {},
   "source": [
    "https://github.com/truera/trulens/blob/main/trulens_eval/examples/expositional/frameworks/llama_index/llama_index_retrievalquality.ipynb\n",
    "\n",
    "åŸºæœ¬æŒ‰ç…§åŽŸæ ·ç¼–å†™çš„ï¼Œä½†æœ€ç»ˆæŠ¥é”™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64b637d7-7726-4b5e-874c-b52436955227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.3 ms, sys: 12.1 ms, total: 23.5 ms\n",
      "Wall time: 1.93 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%capture\n",
    "\n",
    "!pip install llama-index-embeddings-langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d32610b4-1ee6-429e-957b-eb5e6ebb2b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦‘ Tru initialized with db url sqlite:///default.sqlite .\n",
      "ðŸ›‘ Secret keys may be written to the database. See the `database_redact_keys` option of `Tru` to prevent this.\n"
     ]
    }
   ],
   "source": [
    "from trulens_eval import Tru\n",
    "\n",
    "tru = Tru()\n",
    "tru.reset_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c20c454a-1a6a-4167-b4c1-05fdd466954f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23.7 ms, sys: 4.31 ms, total: 28 ms\n",
      "Wall time: 27.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from llama_index.core import Settings\n",
    "from llama_index.llms.openai_like import OpenAILike\n",
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "\n",
    "Settings.chunk_size = 128\n",
    "Settings.chunk_overlap = 16\n",
    "\n",
    "Settings.llm = OpenAILike(\n",
    "    model=\"qwen2\", \n",
    "    api_base=\"http://monkey:11434/v1\", \n",
    "    api_key=\"ollama\",\n",
    "    is_chat_model=True,\n",
    "    temperature=0.1,\n",
    "    request_timeout=60.0\n",
    ")\n",
    "\n",
    "Settings.embed_model =OllamaEmbedding(\n",
    "    model_name=\"quentinz/bge-large-zh-v1.5\",\n",
    "    base_url=\"http://monkey:11434\",\n",
    "    ollama_additional_kwargs={\"mirostat\": 0}, # -mirostat N ä½¿ç”¨ Mirostat é‡‡æ ·ã€‚\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "087c9b65-1763-4e97-b188-b74f251384f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embed_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"/models/paraphrase-multilingual-MiniLM-L12-v2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3cef66f6-bd6e-40d1-b8a0-530dd695ae0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.legacy import ServiceContext\n",
    "from llama_index.readers.web import SimpleWebPageReader\n",
    "\n",
    "documents = SimpleWebPageReader(html_to_text=True).load_data(\n",
    "    [\"https://paulgraham.com/worked.html\"]\n",
    ")\n",
    "\n",
    "# service_context = ServiceContext.from_defaults(embed_model=embed_model,llm=Settings.llm)\n",
    "\n",
    "Settings.embed_model =embed_model\n",
    "\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents,\n",
    "    # service_context=service_context\n",
    ")\n",
    "\n",
    "query_engine = index.as_query_engine(top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11aea551-3a24-43d0-98aa-9257a1405b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Growing up, the author focused on two main activities outside of school: writing short stories as a beginning writer and programming. They did not write essays but instead worked on crafting short stories that lacked plot development, featuring characters with strong emotions they believed made them deep. Additionally, they enjoyed programming but initially had no plans to study it in college, opting instead for philosophy which seemed more powerful and concerned with ultimate truths according to their naive high school perspective.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"What did the author do growing up?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a5c5646-05cb-404e-9b34-d857ddbb58b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from trulens_eval.feedback.provider import OpenAI\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-bJP6QSnUfjAYeYeE505d3eBf63A643BeB0B8E350Df9b7750\"\n",
    "os.environ[\"OPENAI_API_BASE\"] = \"https://ape:3000/v1\"\n",
    "provider = OpenAI(\n",
    "    model_engine=\"qwen2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe422a9b-f987-47b0-b324-eccedac656a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… In context_relevance, input question will be set to __record__.main_input or `Select.RecordInput` .\n",
      "âœ… In context_relevance, input context will be set to __record__.app.query.rets.source_nodes[:].node.text .\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from trulens_eval import Feedback\n",
    "from trulens_eval import TruLlama\n",
    "\n",
    "# Question/statement relevance between question and each context chunk.\n",
    "f_context_relevance = (\n",
    "    Feedback(provider.context_relevance)\n",
    "    .on_input()\n",
    "    .on(TruLlama.select_source_nodes().node.text)\n",
    "    .aggregate(np.mean)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a687148d-5cb7-4212-813a-28a3d03ba031",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Embeddings' object has no attribute '__pydantic_private__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtrulens_eval\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeedback\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Embeddings\n\u001b[0;32m----> 3\u001b[0m f_embed \u001b[38;5;241m=\u001b[39m \u001b[43mEmbeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43membed_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membed_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# f_embed_dist = (\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#     Feedback(f_embed.cosine_distance)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#     .on_input()\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#     .on(TruLlama.select_source_nodes().node.text)\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#     .aggregate(np.mean)\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/trulens_eval/feedback/embeddings.py:35\u001b[0m, in \u001b[0;36mEmbeddings.__init__\u001b[0;34m(self, embed_model)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Instantiates embeddings for feedback functions. \u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;124;03m```\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;124;03mf_embed = feedback.Embeddings(embed_model=embed_model)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03m    embed_model ('Embedder'): Supported embedders taken from llama-index: https://gpt-index.readthedocs.io/en/latest/core_modules/model_modules/embeddings/root.html\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     34\u001b[0m service_context \u001b[38;5;241m=\u001b[39m ServiceContext\u001b[38;5;241m.\u001b[39mfrom_defaults(embed_model\u001b[38;5;241m=\u001b[39membed_model)\n\u001b[0;32m---> 35\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_embed_model\u001b[49m \u001b[38;5;241m=\u001b[39m service_context\u001b[38;5;241m.\u001b[39membed_model\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pydantic/main.py:820\u001b[0m, in \u001b[0;36mBaseModel.__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m    815\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m    816\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m is a ClassVar of `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` and cannot be set on an instance. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    817\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIf you want to set a value on the class, use `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m = value`.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    818\u001b[0m     )\n\u001b[1;32m    819\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _fields\u001b[38;5;241m.\u001b[39mis_valid_field_name(name):\n\u001b[0;32m--> 820\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_private__\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__private_attributes__:\n\u001b[1;32m    821\u001b[0m         _object_setattr(\u001b[38;5;28mself\u001b[39m, name, value)\n\u001b[1;32m    822\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pydantic/main.py:808\u001b[0m, in \u001b[0;36mBaseModel.__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, item):\n\u001b[0;32m--> 808\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Raises AttributeError if appropriate\u001b[39;00m\n\u001b[1;32m    809\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    810\u001b[0m         \u001b[38;5;66;03m# this is the current error\u001b[39;00m\n\u001b[1;32m    811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Embeddings' object has no attribute '__pydantic_private__'"
     ]
    }
   ],
   "source": [
    "from trulens_eval.feedback import Embeddings\n",
    "\n",
    "f_embed = Embeddings(embed_model=embed_model)\n",
    "\n",
    "# f_embed_dist = (\n",
    "#     Feedback(f_embed.cosine_distance)\n",
    "#     .on_input()\n",
    "#     .on(TruLlama.select_source_nodes().node.text)\n",
    "#     .aggregate(np.mean)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16632c2d-0581-4c98-9a0d-d1778ddac5f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
