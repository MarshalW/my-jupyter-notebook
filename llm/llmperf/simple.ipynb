{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebc052d4-efc6-4f08-b6dc-7b32e7b26b41",
   "metadata": {},
   "source": [
    "# LLMPerf 基本使用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941e935b-4a77-43d8-b114-1441ef236368",
   "metadata": {},
   "source": [
    "## 安装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1393701-9a06-4497-8460-473d242db5f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'llmperf'...\n",
      "remote: Enumerating objects: 159, done.\u001b[K\n",
      "remote: Counting objects: 100% (43/43), done.\u001b[K\n",
      "remote: Compressing objects: 100% (22/22), done.\u001b[K\n",
      "remote: Total 159 (delta 24), reused 21 (delta 20), pack-reused 116\u001b[K\n",
      "Receiving objects: 100% (159/159), 247.07 KiB | 634.00 KiB/s, done.\n",
      "Resolving deltas: 100% (76/76), done.\n",
      "/root/notebook/my-jupyter-notebook/llm/llmperf/llmperf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Obtaining file:///root/notebook/my-jupyter-notebook/llm/llmperf/llmperf\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hInstalling collected packages: UNKNOWN\n",
      "  Running setup.py develop for UNKNOWN\n",
      "Successfully installed UNKNOWN-0.0.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCPU times: user 140 ms, sys: 42.4 ms, total: 182 ms\n",
      "Wall time: 13.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# %%capture\n",
    "\n",
    "!rm -rf llmperf\n",
    "\n",
    "!export http_proxy=\"http://myproxy:7890\"\n",
    "!export https_proxy=\"http://myproxy:7890\"\n",
    "\n",
    "# 克隆仓库\n",
    "!git clone https://github.com/ray-project/llmperf.git\n",
    "\n",
    "# 进入仓库目录\n",
    "%cd llmperf\n",
    "\n",
    "!touch setup.cfg\n",
    "\n",
    "# 安装依赖\n",
    "!pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a92ebbee-af71-453a-aa71-cebd762a10be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 993 µs, sys: 8.05 ms, total: 9.04 ms\n",
      "Wall time: 266 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# https://huggingface.co/hf-internal-testing/llama-tokenizer/tree/main\n",
    "# 从下载的目录复制\n",
    "!mkdir hf-internal-testing\n",
    "!cp -r /models/llama-tokenizer hf-internal-testing\n",
    "# # 或者设置代理代码会自动下载\n",
    "# %env http_proxy=\"http:/myproxy:7890\"\n",
    "# %env https_proxy=\"http:/myproxy:7890\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a09fdc-dbc1-4fbd-b202-d4d6cb713817",
   "metadata": {},
   "source": [
    "## 负载测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e207414a-1e26-4f9d-a242-f2e334e23eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: OPENAI_API_KEY=ollama\n",
      "env: OPENAI_API_BASE=http://monkey:11434/v1\n",
      "2024-07-29 11:34:52,671\tINFO worker.py:1781 -- Started a local Ray instance.\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:07<00:00,  3.84s/it]\n",
      "\\Results for token benchmark for qwen2 queried with the openai api.\n",
      "\n",
      "inter_token_latency_s\n",
      "    p25 = 0.017874787592801773\n",
      "    p50 = 0.019646871597698498\n",
      "    p75 = 0.021418955602595224\n",
      "    p90 = 0.02248220600553326\n",
      "    p95 = 0.022836622806512604\n",
      "    p99 = 0.02312015624729608\n",
      "    mean = 0.019646871597698498\n",
      "    min = 0.016102703587905047\n",
      "    max = 0.02319103960749195\n",
      "    stddev = 0.005012210466778759\n",
      "ttft_s\n",
      "    p25 = 0.5501839839853346\n",
      "    p50 = 0.8344089183956385\n",
      "    p75 = 1.1186338528059423\n",
      "    p90 = 1.2891688134521246\n",
      "    p95 = 1.3460138003341853\n",
      "    p99 = 1.391489789839834\n",
      "    mean = 0.8344089183956385\n",
      "    min = 0.2659590495750308\n",
      "    max = 1.4028587872162461\n",
      "    stddev = 0.8039095140153102\n",
      "end_to_end_latency_s\n",
      "    p25 = 3.267872414784506\n",
      "    p50 = 3.5082656065933406\n",
      "    p75 = 3.7486587984021753\n",
      "    p90 = 3.8928947134874763\n",
      "    p95 = 3.940973351849243\n",
      "    p99 = 3.979436262538657\n",
      "    mean = 3.5082656065933406\n",
      "    min = 3.0274792229756713\n",
      "    max = 3.98905199021101\n",
      "    stddev = 0.6799346243164216\n",
      "request_output_throughput_token_per_s\n",
      "    p25 = 47.862977156418204\n",
      "    p50 = 52.607940202696504\n",
      "    p75 = 57.352903248974805\n",
      "    p90 = 60.19988107674178\n",
      "    p95 = 61.148873685997444\n",
      "    p99 = 61.908067773401974\n",
      "    mean = 52.607940202696504\n",
      "    min = 43.1180141101399\n",
      "    max = 62.097866295253105\n",
      "    stddev = 13.420782186011857\n",
      "number_input_tokens\n",
      "    p25 = 548.75\n",
      "    p50 = 559.5\n",
      "    p75 = 570.25\n",
      "    p90 = 576.7\n",
      "    p95 = 578.85\n",
      "    p99 = 580.57\n",
      "    mean = 559.5\n",
      "    min = 538\n",
      "    max = 581\n",
      "    stddev = 30.405591591021544\n",
      "number_output_tokens\n",
      "    p25 = 176.0\n",
      "    p50 = 180.0\n",
      "    p75 = 184.0\n",
      "    p90 = 186.4\n",
      "    p95 = 187.2\n",
      "    p99 = 187.84\n",
      "    mean = 180.0\n",
      "    min = 172\n",
      "    max = 188\n",
      "    stddev = 11.313708498984761\n",
      "Number Of Errored Requests: 0\n",
      "Overall Output Throughput: 46.85670620642702\n",
      "Number Of Completed Requests: 2\n",
      "Completed Requests Per Minute: 15.618902068809009\n",
      "\u001b[0mCPU times: user 137 ms, sys: 21.9 ms, total: 159 ms\n",
      "Wall time: 14.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# 设置环境变量\n",
    "%env OPENAI_API_KEY=ollama\n",
    "%env OPENAI_API_BASE=http://monkey:11434/v1\n",
    "\n",
    "# !python3 token_benchmark_ray.py \\\n",
    "!PYTHONPATH=$(pwd)/src python3 token_benchmark_ray.py \\\n",
    "--model \"qwen2\" \\\n",
    "--mean-input-tokens 550 \\\n",
    "--stddev-input-tokens 150 \\\n",
    "--mean-output-tokens 150 \\\n",
    "--stddev-output-tokens 10 \\\n",
    "--max-num-completed-requests 2 \\\n",
    "--timeout 600 \\\n",
    "--num-concurrent-requests 1 \\\n",
    "--results-dir \"result_outputs\" \\\n",
    "--llm-api openai \\\n",
    "--additional-sampling-params '{}'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7427d58b-fa38-45f2-88e1-9cc01f71faf1",
   "metadata": {},
   "source": [
    "## 正确性测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25d1df4f-180f-4945-afb8-72f59ad6df8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: OPENAI_API_KEY=ollama\n",
      "env: OPENAI_API_BASE=http://monkey:11434/v1\n",
      "2024-07-29 11:35:06,702\tINFO worker.py:1781 -- Started a local Ray instance.\n",
      "100%|█████████████████████████████████████████| 150/150 [00:11<00:00, 13.35it/s]\n",
      "Mismatched and errored requests.\n",
      "    mismatched request: 8800, expected: 8880\n",
      "\n",
      "Results for llm correctness test for qwen2 queried with the openai api.\n",
      "Errors: 0, Error rate: 0.0\n",
      "Mismatched: 1, Mismatch rate: 0.006666666666666667\n",
      "Completed: 150\n",
      "Completed without errors: 150\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# 设置环境变量\n",
    "%env OPENAI_API_KEY=ollama\n",
    "%env OPENAI_API_BASE=http://monkey:11434/v1\n",
    "\n",
    "!PYTHONPATH=$(pwd)/src python3 llm_correctness.py \\\n",
    "--model \"qwen2\" \\\n",
    "--max-num-completed-requests 150 \\\n",
    "--timeout 600 \\\n",
    "--num-concurrent-requests 10 \\\n",
    "--results-dir \"result_outputs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba089631-8226-48c7-b3ab-cec1ba8ad567",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
