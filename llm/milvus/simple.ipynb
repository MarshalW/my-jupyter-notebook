{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4742260-f40e-445c-beff-2640bc7bddc6",
   "metadata": {},
   "source": [
    "# milvus lite 测试示例"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df0750b-0a1b-4ee9-bb0b-33c37c33ad3c",
   "metadata": {},
   "source": [
    "## 准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "898dae90-66c6-440b-8c64-b754aa553f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 67.2 ms, sys: 22.2 ms, total: 89.4 ms\n",
      "Wall time: 21.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%capture\n",
    "\n",
    "!pip install milvus\n",
    "!pip install pymilvus\n",
    "!pip install llama-index-vector-stores-milvus\n",
    "!pip install llama-index-embeddings-ollama\n",
    "!pip install llama-index-llms-openai-like\n",
    "!pip install llama_index.core\n",
    "!pip install llama-index-readers-file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78e56a78-9c35-4ec2-b147-b9000ac39c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.76 s, sys: 658 ms, total: 3.42 s\n",
      "Wall time: 4.62 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.core import StorageContext\n",
    "from IPython.display import Markdown, display\n",
    "from llama_index.core import Settings\n",
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "\n",
    "from llama_index.llms.openai_like import OpenAILike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cfe199e-c5ce-40c6-9643-557c9f6fb5d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_Settings(_llm=None, _embed_model=None, _callback_manager=None, _tokenizer=None, _node_parser=SentenceSplitter(include_metadata=True, include_prev_next_rel=True, callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x7fdfc23f75b0>, id_func=<function default_id_func at 0x7fe0806e0a60>, chunk_size=128, chunk_overlap=10, separator=' ', paragraph_separator='\\n\\n\\n', secondary_chunking_regex='[^,.;。？！]+[,.;。？！]?'), _prompt_helper=None, _transformations=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Settings.chunk_size=128\n",
    "Settings.chunk_overlap=10\n",
    "\n",
    "Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "336ed40e-cdde-4c7d-a167-cbf5c85150f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 201 µs, sys: 23 µs, total: 224 µs\n",
      "Wall time: 228 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "llm = OpenAILike(model=\"xiaoyu\", \n",
    "                 api_base=\"http://192.168.0.72:3000/v1\", \n",
    "                 api_key=\"sk-bJP6QSnUfjAYeYeE505d3eBf63A643BeB0B8E350Df9b7750\",\n",
    "                 is_chat_model=True,\n",
    "                 temperature=0.1\n",
    "                )\n",
    "\n",
    "Settings.llm =llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fe433d3-4cba-46dd-b31f-89a93694a50b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 447 ms, sys: 37.1 ms, total: 484 ms\n",
      "Wall time: 618 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# 初始化全局 embedding 模型\n",
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "\n",
    "ollama_embedding = OllamaEmbedding(\n",
    "    model_name=\"dztech/bge-large-zh:v1.5\",\n",
    "    # model_name=\"bge-m3:latest\",\n",
    "    base_url=\"http://192.168.0.72:11435\",\n",
    "    ollama_additional_kwargs={\"mirostat\": 0}, # -mirostat N 使用 Mirostat 采样。\n",
    ")\n",
    "\n",
    "Settings.embed_model = ollama_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e1fced-43df-4d11-ad39-da9ef8967ba6",
   "metadata": {},
   "source": [
    "## 启动 milvus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6e21f68-1388-4850-ba34-61b9cc659baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v2.3.5-lite\n",
      "CPU times: user 3.49 s, sys: 360 ms, total: 3.85 s\n",
      "Wall time: 6.83 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "19530"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from milvus import default_server\n",
    "from pymilvus import connections, utility\n",
    "\n",
    "default_server.set_base_dir('milvus_data')\n",
    "\n",
    "# (OPTIONAL) if you want cleanup previous data\n",
    "default_server.cleanup()\n",
    "\n",
    "# Start your milvus server\n",
    "default_server.start()\n",
    "\n",
    "# Now you could connect with localhost and the given port\n",
    "# Port is defined by default_server.listen_port\n",
    "connections.connect(host='127.0.0.1', port=default_server.listen_port)\n",
    "\n",
    "# Check if the server is ready.\n",
    "print(utility.get_server_version())\n",
    "\n",
    "# Stop your milvus server\n",
    "# default_server.stop()\n",
    "\n",
    "default_server.listen_port"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd935c52-3246-45cf-a56c-c061553d7fa9",
   "metadata": {},
   "source": [
    "## 加载索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db26d1fe-a473-4532-bc98-a269e06c6c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document ID: f47bbb9f-c0fb-4a99-9135-4a360c6400be\n",
      "CPU times: user 13.5 ms, sys: 12 µs, total: 13.5 ms\n",
      "Wall time: 24.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# load documents\n",
    "documents = SimpleDirectoryReader(\"./books/\").load_data()\n",
    "print(\"Document ID:\", documents[0].doc_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c50d0cb-3d20-43a0-8318-8ed9627f3649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.9 s, sys: 806 ms, total: 17.7 s\n",
      "Wall time: 1min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from llama_index.core import VectorStoreIndex, StorageContext\n",
    "from llama_index.vector_stores.milvus import MilvusVectorStore\n",
    "\n",
    "vector_store = MilvusVectorStore(dim=1024, overwrite=True)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents, storage_context=storage_context\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2f1ad8-6829-43ac-9504-03175520310e",
   "metadata": {},
   "source": [
    "## 基本嵌入查询"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce556548-c3c2-4fa8-8ecc-97f8636b76ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 41.3 ms, sys: 0 ns, total: 41.3 ms\n",
      "Wall time: 55.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Query Data\n",
    "query_engine = index.as_query_engine(\n",
    "    streaming=True,\n",
    "    similarity_top_k=100,\n",
    "    similarity_cutoff=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea767091-c7ee-47e9-8641-4f74e39c6617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "他的妻子是孙柔嘉。\n",
      "CPU times: user 168 ms, sys: 11.4 ms, total: 180 ms\n",
      "Wall time: 13.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "streaming_response = query_engine.query(\"方鸿渐的妻子是谁\")\n",
    "streaming_response.print_response_stream()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4ad9cd5-28dc-4756-98fa-4e344ef52835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "由于提供的上下文中并未提及方鸿渐的父亲姓名，所以我无法直接给出答案。\n",
      "\n",
      "CPU times: user 126 ms, sys: 3.53 ms, total: 130 ms\n",
      "Wall time: 10.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "streaming_response = query_engine.query(\"方鸿渐的父亲是谁，说出他的名字\")\n",
    "streaming_response.print_response_stream()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae6bee6f-00b5-4452-bc59-c4c91e96f1ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "书中提及的“局部真理”暗示的是一个观点在特定情况下显得有道理，但它并非普遍适用或绝对正确，可能局限于某个特定情境或个体经验。这就像教书的例子，尽管个人的经验有限，但在特定的教学环境中仍能派上用场。\n",
      "CPU times: user 326 ms, sys: 18.2 ms, total: 344 ms\n",
      "Wall time: 23.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "streaming_response = query_engine.query(\"文中提到的局部真理是啥意思\")\n",
    "streaming_response.print_response_stream()\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227e2641-cd50-4f42-94fd-dd0b7c9ac193",
   "metadata": {},
   "source": [
    "## rerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ebc56634-9d5e-4af2-9756-f18df5a65745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.37 s, sys: 1.57 s, total: 2.94 s\n",
      "Wall time: 15.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from llama_index.core.postprocessor import SentenceTransformerRerank\n",
    "\n",
    "reranker = SentenceTransformerRerank(model='/models/bge-reranker-v2-m3', top_n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "06f0c096-4dd9-4051-a920-2c619731ac9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 217 µs, sys: 0 ns, total: 217 µs\n",
      "Wall time: 223 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "query_engine = index.as_query_engine(\n",
    "    streaming=True,\n",
    "    similarity_top_k=100,\n",
    "    node_postprocessors=[reranker]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4d936734-69ee-4da8-8a5f-d7aae67a630a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "方鸿渐的妻子是孙柔嘉。\n",
      "CPU times: user 740 ms, sys: 8.24 ms, total: 748 ms\n",
      "Wall time: 2.07 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "streaming_response = query_engine.query(\"方鸿渐的妻子是谁\")\n",
    "streaming_response.print_response_stream()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cc35e242-73ef-4bd4-a4fc-ea0cfc274715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "方鸿渐的父亲没有直接的名字提及。不过，从上下文可以推断他可能是一个有影响力的人物，因为唐小姐提到“你昨天闯了大祸，知道么？”并且鹏图也提到了“就是法国的博士，报上见过的”，这可能暗示他与某个知名人士有关。然而，具体的名字并未在给定的文本中提供。\n",
      "CPU times: user 855 ms, sys: 11 ms, total: 866 ms\n",
      "Wall time: 4.71 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "streaming_response = query_engine.query(\"方鸿渐的父亲是谁，说出他的名字\")\n",
    "streaming_response.print_response_stream()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "055c0cc1-78e3-412b-a396-c6b71bfa980f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文中提到的“局部真理”是指鲍小姐虽然并非赤裸裸的（一丝不挂），但她的某些特质或情况被认为是接近或代表了“真理”，这可能是一种比喻，暗示她具有某种真实或实在的一面，但并不全面。这里的“局部”强调不是完整的、绝对的真理，而是部分真实的反映。\n",
      "CPU times: user 805 ms, sys: 11.5 ms, total: 817 ms\n",
      "Wall time: 4.26 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "streaming_response = query_engine.query(\"文中提到的局部真理是啥意思\")\n",
    "streaming_response.print_response_stream()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c65c75-69d5-4fb7-8e75-56207aa5c51c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
