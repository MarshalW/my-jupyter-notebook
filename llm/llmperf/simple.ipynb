{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebc052d4-efc6-4f08-b6dc-7b32e7b26b41",
   "metadata": {},
   "source": [
    "# LLMPerf 基本使用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941e935b-4a77-43d8-b114-1441ef236368",
   "metadata": {},
   "source": [
    "## 安装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1393701-9a06-4497-8460-473d242db5f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26.1 ms, sys: 10.6 ms, total: 36.7 ms\n",
      "Wall time: 7.84 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%capture\n",
    "\n",
    "# 克隆仓库\n",
    "!git clone https://github.com/ray-project/llmperf.git\n",
    "\n",
    "# 进入仓库目录\n",
    "%cd llmperf\n",
    "!git checkout v2.0\n",
    "\n",
    "# 安装依赖\n",
    "!pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97583afe-4d3a-4828-8294-6d126a90499e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 77 ms, sys: 39 ms, total: 116 ms\n",
      "Wall time: 40.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%capture\n",
    "\n",
    "!pip install ray\n",
    "!pip install pydantic<2.5\n",
    "!pip install pytest>=6.0\n",
    "!pip install seaborn>=0.11\n",
    "!pip install awscli>=1.22\n",
    "!pip install typer>=0.4\n",
    "!pip install litellm>=0.1.738\n",
    "!pip install num2words\n",
    "!pip install transformers\n",
    "!pip install tqdm\n",
    "!pip install boto3\n",
    "!pip install google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a09fdc-dbc1-4fbd-b202-d4d6cb713817",
   "metadata": {},
   "source": [
    "## 负载测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e207414a-1e26-4f9d-a242-f2e334e23eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: OPENAI_API_KEY=ollama\n",
      "env: OPENAI_API_BASE=http://monkey:11434/v1\n",
      "2024-07-27 18:44:33,402\tINFO worker.py:1781 -- Started a local Ray instance.\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:07<00:00,  3.93s/it]\n",
      "\\Results for token benchmark for qwen2 queried with the openai api.\n",
      "\n",
      "inter_token_latency_s\n",
      "    p25 = 0.017240031717207144\n",
      "    p50 = 0.018820193830246804\n",
      "    p75 = 0.020400355943286465\n",
      "    p90 = 0.02134845321111026\n",
      "    p95 = 0.021664485633718193\n",
      "    p99 = 0.02191731157180454\n",
      "    mean = 0.018820193830246804\n",
      "    min = 0.015659869604167483\n",
      "    max = 0.021980518056326125\n",
      "    stddev = 0.0044693733820176315\n",
      "ttft_s\n",
      "    p25 = 0.47558959864545614\n",
      "    p50 = 0.7410630520898849\n",
      "    p75 = 1.0065365055343136\n",
      "    p90 = 1.165820577600971\n",
      "    p95 = 1.2189152682898565\n",
      "    p99 = 1.261391020840965\n",
      "    mean = 0.7410630520898849\n",
      "    min = 0.2101161452010274\n",
      "    max = 1.2720099589787424\n",
      "    stddev = 0.7508723166222672\n",
      "end_to_end_latency_s\n",
      "    p25 = 3.258551472914405\n",
      "    p50 = 3.557205381570384\n",
      "    p75 = 3.8558592902263626\n",
      "    p90 = 4.03505163541995\n",
      "    p95 = 4.094782417151146\n",
      "    p99 = 4.142567042536102\n",
      "    mean = 3.557205381570384\n",
      "    min = 2.9598975642584264\n",
      "    max = 4.154513198882341\n",
      "    stddev = 0.8447208161540413\n",
      "request_output_throughput_token_per_s\n",
      "    p25 = 41.8069950243879\n",
      "    p50 = 45.101656030185225\n",
      "    p75 = 48.39631703598254\n",
      "    p90 = 50.37311363946093\n",
      "    p95 = 51.03204584062039\n",
      "    p99 = 51.559191601547965\n",
      "    mean = 45.101656030185225\n",
      "    min = 38.512334018590586\n",
      "    max = 51.69097804177986\n",
      "    stddev = 9.318708555640697\n",
      "number_input_tokens\n",
      "    p25 = 226.25\n",
      "    p50 = 236.5\n",
      "    p75 = 246.75\n",
      "    p90 = 252.9\n",
      "    p95 = 254.95\n",
      "    p99 = 256.59\n",
      "    mean = 236.5\n",
      "    min = 216\n",
      "    max = 257\n",
      "    stddev = 28.991378028648448\n",
      "number_output_tokens\n",
      "    p25 = 189.0\n",
      "    p50 = 189.0\n",
      "    p75 = 189.0\n",
      "    p90 = 189.0\n",
      "    p95 = 189.0\n",
      "    p99 = 189.0\n",
      "    mean = 189.0\n",
      "    min = 189\n",
      "    max = 189\n",
      "    stddev = 0.0\n",
      "Number Of Errored Requests: 0\n",
      "Overall Output Throughput: 48.12917236031577\n",
      "Number Of Completed Requests: 2\n",
      "Completed Requests Per Minute: 15.27910233660818\n",
      "\u001b[0mCPU times: user 135 ms, sys: 35.8 ms, total: 170 ms\n",
      "Wall time: 14.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# 设置环境变量\n",
    "%env OPENAI_API_KEY=ollama\n",
    "%env OPENAI_API_BASE=http://monkey:11434/v1\n",
    "\n",
    "# https://huggingface.co/hf-internal-testing/llama-tokenizer/tree/main\n",
    "# 从下载的目录复制\n",
    "!mkdir hf-internal-testing\n",
    "!cp -r /models/llama-tokenizer hf-internal-testing\n",
    "# # 或者设置代理代码会自动下载\n",
    "# %env http_proxy=\"http:/192.168.0.134:7890\"\n",
    "# %env https_proxy=\"http:/192.168.0.134:7890\"\n",
    "\n",
    "\n",
    "!PYTHONPATH=$(pwd)/src python3 token_benchmark_ray.py \\\n",
    "--model \"qwen2\" \\\n",
    "--mean-input-tokens 550 \\\n",
    "--stddev-input-tokens 150 \\\n",
    "--mean-output-tokens 150 \\\n",
    "--stddev-output-tokens 10 \\\n",
    "--max-num-completed-requests 2 \\\n",
    "--timeout 600 \\\n",
    "--num-concurrent-requests 1 \\\n",
    "--results-dir \"result_outputs\" \\\n",
    "--llm-api openai \\\n",
    "--additional-sampling-params '{}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce260b7-b0b9-48bb-9644-2b7adc9287a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
