{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e31f4040-e889-41b2-ae1a-96c2a44d8596",
   "metadata": {},
   "source": [
    "# 使用智谱ai模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775d5b17-2f4a-43af-ad16-9692053822fa",
   "metadata": {},
   "source": [
    "结论：\n",
    "\n",
    "- LLM 可以使用 `openai_like`\n",
    "- Embedding 在 LlamaIndex 中没有相应的实现，LangChain 有，LlamaIndex 有包装 LangChain Embedding 的实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55026dcc-7e41-4bf9-822b-c5befcce28e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.75 ms, sys: 7.44 ms, total: 16.2 ms\n",
      "Wall time: 1.79 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%capture\n",
    "\n",
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ffc07a1-a083-4bad-b1c5-65c42af5510e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.3 ms, sys: 215 µs, total: 5.52 ms\n",
      "Wall time: 4.94 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"ZHIPU_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6dce4f43-8576-416c-80ad-bd54cde9f1c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.85 s, sys: 343 ms, total: 3.19 s\n",
      "Wall time: 2.81 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from llama_index.llms.openai_like import OpenAILike\n",
    "from llama_index.core import Settings\n",
    "\n",
    "model=\"GLM-4-Flash\"\n",
    "llm = OpenAILike(\n",
    "    model=model, \n",
    "    api_base=\"https://open.bigmodel.cn/api/paas/v4/\", \n",
    "    api_key=api_key,\n",
    "    is_chat_model=True,\n",
    "    temperature=0.1,\n",
    "    request_timeout=60.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15950542-cb84-4e4d-a065-2b2a4aee0b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "置信区间（Confidence Interval，简称CI）是统计学中用来估计总体参数范围的一种方法。它是一个区间估计，用于表示对总体参数的一个估计值，并给出该估计值的不确定性程度。\n",
      "\n",
      "具体来说，置信区间是指在一定的置信水平（通常用百分比表示，如95%）下，对总体参数（如总体均值、总体比例等）的一个估计范围。在这个范围内，我们可以认为总体参数的真实值有很高的概率（即置信水平）落在该区间内。\n",
      "\n",
      "例如，如果我们想估计一个班级学生的平均身高，我们可以随机抽取一部分学生进行测量，然后根据这些样本数据计算出平均身高。这个平均身高就是一个点估计值。但是，由于样本的随机性，我们无法确定这个点估计值是否准确。因此，我们可以构造一个置信区间，比如95%的置信区间，来表示我们估计的平均身高有95%的概率落在某个范围内。\n",
      "\n",
      "置信区间的计算通常需要以下步骤：\n",
      "\n",
      "1. 确定置信水平：通常选择95%或99%作为置信水平。\n",
      "2. 计算标准误差：标准误差是样本统计量（如样本均值）的标准差，它反映了样本统计量与总体参数之间的差异。\n",
      "3. 确定置信区间宽度：根据标准误差和置信水平，可以计算出置信区间的宽度。\n",
      "4. 计算置信区间：将点估计值（如样本均值）加上或减去置信区间宽度的一半，得到置信区间的上下限。\n",
      "\n",
      "总之，置信区间是一种对总体参数进行估计的方法，它能够给出估计值的不确定性程度，并在一定程度上反映了估计结果的可靠性。CPU times: user 186 ms, sys: 12.3 ms, total: 198 ms\n",
      "Wall time: 6.32 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "resp = llm.stream_complete(\"介绍下什么叫置信区间\")\n",
    "\n",
    "for r in resp:\n",
    "    print(r.delta, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea0ed9d-fa81-4d61-b592-4f6308975a81",
   "metadata": {},
   "source": [
    "## 设置和使用 Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "517c16e2-661d-4e25-8cbb-919fc1875a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.5 ms, sys: 13.3 ms, total: 26.8 ms\n",
      "Wall time: 3.66 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%capture\n",
    "\n",
    "!pip install langchain-community\n",
    "!pip install zhipuai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00f5ada1-aaa2-4bae-8c2c-dcc4d36b4de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19 µs, sys: 2 µs, total: 21 µs\n",
      "Wall time: 22.6 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "os.environ[\"ZHIPUAI_API_KEY\"]=api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8a06969-766d-47ac-90d7-934eaa63aa4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 239 ms, sys: 11.3 ms, total: 250 ms\n",
      "Wall time: 412 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.015960693, 2.503395e-05, -0.00014424324, -0.003540039, -0.02571106]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from langchain_community.embeddings import ZhipuAIEmbeddings\n",
    "\n",
    "embeddings = ZhipuAIEmbeddings(\n",
    "    model=\"embedding-3\",\n",
    "    # With the `embedding-3` class\n",
    "    # of models, you can specify the size\n",
    "    # of the embeddings you want returned.\n",
    "    # dimensions=1024\n",
    ")\n",
    "\n",
    "embeddings.embed_query(\"风急天高猿啸哀\")[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7316f599-483e-4720-b0e4-aa4cdfcb282c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.08 ms, sys: 8.22 ms, total: 15.3 ms\n",
      "Wall time: 1.86 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%capture\n",
    "\n",
    "!pip install llama-index-embeddings-langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73aa258d-d941-42fb-bda1-d3257f26e1cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048 [0.015960693, 2.503395e-05, -0.00014424324, -0.003540039, -0.02571106]\n",
      "CPU times: user 17.2 ms, sys: 3.32 ms, total: 20.5 ms\n",
      "Wall time: 184 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from llama_index.embeddings.langchain import LangchainEmbedding\n",
    "\n",
    "embed_model = LangchainEmbedding(embeddings)\n",
    "\n",
    "embeddings = embed_model.get_text_embedding(\n",
    "    \"风急天高猿啸哀\"\n",
    ")\n",
    "print(len(embeddings), embeddings[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd90c9c-0906-4062-bc1a-622b9ca357da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
