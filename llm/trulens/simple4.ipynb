{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90e40ded-c13a-41c9-8aa5-e231cc04000a",
   "metadata": {},
   "source": [
    "测试使用： https://github.com/truera/trulens/issues/1215\n",
    "\n",
    "根据bug回复写出一个原型，但是依然是 `qs_relevance None`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec5818c6-7b69-4470-891e-480575463be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10 µs, sys: 2 µs, total: 12 µs\n",
      "Wall time: 12.9 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import os\n",
    "\n",
    "base_url = \"http://ape:3000/v1\"\n",
    "api_key = \"sk-bJP6QSnUfjAYeYeE505d3eBf63A643BeB0B8E350Df9b7750\"\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "os.environ[\"OPENAI_API_BASE\"] = base_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7043d384-5a98-441f-9a58-cb5bf4b1301c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Where is Germany?</td>\n",
       "      <td>Germany is in Europe</td>\n",
       "      <td>Germany is a country located in Europe.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the capital of France?</td>\n",
       "      <td>The capital of France is Paris</td>\n",
       "      <td>France is a country in Europe and its capital ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           prompt                        response  \\\n",
       "0               Where is Germany?            Germany is in Europe   \n",
       "1  What is the capital of France?  The capital of France is Paris   \n",
       "\n",
       "                                             context  \n",
       "0            Germany is a country located in Europe.  \n",
       "1  France is a country in Europe and its capital ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'prompt': ['Where is Germany?', 'What is the capital of France?'],\n",
    "    'response': ['Germany is in Europe', 'The capital of France is Paris'],\n",
    "    'context': ['Germany is a country located in Europe.', 'France is a country in Europe and its capital is Paris.']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b131e09e-e89c-4cfc-b96d-f9b83a9a838e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.83 s, sys: 493 ms, total: 6.32 s\n",
      "Wall time: 6.14 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from trulens_eval.schema.feedback import Select\n",
    "from trulens_eval.tru_virtual import VirtualApp\n",
    "from trulens_eval.tru_virtual import VirtualRecord\n",
    "\n",
    "virtual_app = dict(\n",
    "    llm=dict(\n",
    "        modelname=\"some llm component model name\"\n",
    "    ),\n",
    "    template=\"information about the template I used in my app\",\n",
    "    debug=\"all of these fields are completely optional\"\n",
    ")\n",
    "\n",
    "virtual_app = VirtualApp(virtual_app) # can start with the prior dictionary\n",
    "virtual_app[Select.RecordCalls.llm.maxtokens] = 1024\n",
    "\n",
    "retriever_component = Select.RecordCalls.retriever\n",
    "virtual_app[retriever_component] = \"this is the retriever component\"\n",
    "\n",
    "context_call = retriever_component.get_context\n",
    "\n",
    "data_dict = df.to_dict('records')\n",
    "\n",
    "data = []\n",
    "\n",
    "for record in data_dict:\n",
    "    rec = VirtualRecord(\n",
    "        main_input=record['prompt'],\n",
    "        main_output=record['response'],\n",
    "        calls=\n",
    "            {\n",
    "                context_call: dict(\n",
    "                    args=[record['prompt']],\n",
    "                    rets=[record['context']]\n",
    "                )\n",
    "            }\n",
    "        )\n",
    "    data.append(rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d995d6a-c19f-40b2-b1b4-69e7df4caa6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ In qs_relevance, input question will be set to __record__.main_input or `Select.RecordInput` .\n",
      "✅ In qs_relevance, input context will be set to __record__.app.retriever.get_context.rets[:] .\n",
      "CPU times: user 54.6 ms, sys: 0 ns, total: 54.6 ms\n",
      "Wall time: 53.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from trulens_eval.feedback.feedback import Feedback\n",
    "from trulens_eval.feedback.provider import OpenAI\n",
    "# from dotenv import load_dotenv\n",
    "# load_dotenv()\n",
    "import os\n",
    "\n",
    "fopenai = OpenAI(\n",
    "    base_url = \"http://ape:3000\",\n",
    "    api_key = api_key\n",
    ")\n",
    "\n",
    "# Select context to be used in feedback. We select the return values of the\n",
    "# virtual `get_context` call in the virtual `retriever` component. Names are\n",
    "# arbitrary except for `rets`.\n",
    "context = context_call.rets[:]\n",
    "\n",
    "# Question/statement relevance between question and each context chunk.\n",
    "f_context_relevance = (\n",
    "    Feedback(fopenai.qs_relevance)\n",
    "    .on_input()\n",
    "    .on(context)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c437a116-adf0-4a20-bddc-3a4db277900a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qs_relevance None\n",
      "hello\n",
      "CPU times: user 355 ms, sys: 4.55 ms, total: 359 ms\n",
      "Wall time: 14.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from trulens_eval.tru_virtual import TruVirtual\n",
    "\n",
    "virtual_recorder = TruVirtual(\n",
    "    app_id=\"a virtual app\",\n",
    "    app=virtual_app,\n",
    "    feedbacks=[f_context_relevance]\n",
    ")\n",
    "\n",
    "temp = []\n",
    "\n",
    "for record in data:\n",
    "    result = virtual_recorder.add_record(record=record)\n",
    "    temp.append(result)\n",
    "\n",
    "for feedback, feedback_result in rec.wait_for_feedback_results().items():\n",
    "    print(feedback.name, feedback_result.result)\n",
    "    print('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6acd03b-86ab-4e37-b2ce-6f5e19d1360a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
